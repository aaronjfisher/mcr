% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hinge_mcr.r
\name{optimize_hinge_general}
\alias{optimize_hinge_general}
\title{Optimize a linear classifier with possibly negative observation weights}
\usage{
optimize_hinge_general(y, X, reg_matrix = diag(p), n = length(y),
  case.weights = rep(1/n, n), reg_threshold, K = 1000, p = dim(X)[2],
  start = NULL, constr_tol = 10^-4, sparse_warning = TRUE,
  maxit_SA = 1000, extra_step_NM = TRUE, short_cg_lim = 15,
  long_cg_lim = 500, ignore_below_zero = TRUE)
}
\arguments{
\item{y}{outcome vector with elements -1 or 1.}

\item{X}{covariate matrix (n x p), which should not contain an interecept or constant column.}

\item{reg_matrix}{Matrix R, where w'Rw is the penalty of a coefficient vector w.}

\item{n}{sample size}

\item{case.weights}{vector of numeric multipliers (possibly negative) for each observation, when computing loss summation.}

\item{reg_threshold}{Value for w'Rw above which the penalty is applied}

\item{K}{penalty multiplier for w'Rw}

\item{p}{covariate dimension}

\item{start}{starting value for coefficient vector}

\item{constr_tol}{buffer for regularization, after which a penalty is applied}

\item{sparse_warning}{warn user if intercept column is detected}

\item{maxit_SA}{number of iterations for SA steps}

\item{extra_step_NM}{whether to follow the SA search with an additional Nelder-Mead search}

\item{short_cg_lim}{tuning parameter used to set initial value of the search}

\item{long_cg_lim}{how many gradient-based steps to take at each SA iteration}

\item{ignore_below_zero}{stop SA search if a value is discovered below zero. This is irrelevant if weights are positive, and is useful in MCR binary search, but may cause problems for other applications of this function beyond MCR.}
}
\value{
a linear coefficient vector
}
\description{
The optimization uses simulated annealing (SA), with a gradient-based search at each step.
}
